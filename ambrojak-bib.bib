@article{chandola2009,
author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
title = {Anomaly detection: A survey},
year = {2009},
issue_date = {July 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/1541880.1541882},
doi = {10.1145/1541880.1541882},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {15},
numpages = {58},
keywords = {Anomaly detection, outlier detection}
}

@article{outlierSurvey,
author = {Domingues, Rémi and Filippone, Maurizio and Michiardi, Pietro and Zouaoui, Jihane},
title = {A comparative evaluation of outlier detection algorithms},
year = {2018},
issue_date = {February 2018},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {74},
number = {C},
issn = {0031-3203},
url = {https://doi.org/10.1016/j.patcog.2017.09.037},
doi = {10.1016/j.patcog.2017.09.037},
abstract = {Experimental comparison and analysis of unsupervised outlier detection techniques.Based on ROC, precision-recall, computation time, memory usage and robustness.Extend a nonparametric Bayesian method to model numerical and categorical features.Experiments make use of novel industrial datasets and assess generalization abilities. We survey unsupervised machine learning algorithms in the context of outlier detection. This task challenges state-of-the-art methods from a variety of research fields to applications including fraud detection, intrusion detection, medical diagnoses and data cleaning. The selected methods are benchmarked on publicly available datasets and novel industrial datasets. Each method is then submitted to extensive scalability, memory consumption and robustness tests in order to build a full overview of the algorithms characteristics.},
journal = {Pattern Recogn.},
month = feb,
pages = {406–421},
numpages = {16},
keywords = {Variational inference, Outlier detection, Novelty detection, Isolation forest, Fraud detection}
}
@INPROCEEDINGS{isoForest,
  author={Liu, Fei Tony and Ting, Kai Ming and Zhou, Zhi-Hua},
  booktitle={2008 Eighth IEEE International Conference on Data Mining}, 
  title={Isolation Forest}, 
  year={2008},
  volume={},
  number={},
  pages={413-422},
  keywords={Application software;Credit cards;Detectors;Constraint optimization;Data mining;Information technology;Laboratories;Isolation technology;Performance evaluation;Astronomy;anomaly detection;outlier detection;novelty detection;isolation forest;binary trees;model based},
  doi={10.1109/ICDM.2008.17}
}
@article{10.1145/335191.335388,
author = {Breunig, Markus M. and Kriegel, Hans-Peter and Ng, Raymond T. and Sander, J\"{o}rg},
title = {LOF: identifying density-based local outliers},
year = {2000},
issue_date = {June 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {0163-5808},
url = {https://doi.org/10.1145/335191.335388},
doi = {10.1145/335191.335388},
abstract = {For many KDD applications, such as detecting criminal activities in E-commerce, finding the rare instances or the outliers, can be more interesting than finding the common patterns. Existing work in outlier detection regards being an outlier as a binary property. In this paper, we contend that for many scenarios, it is more meaningful to assign to each object a degree of being an outlier. This degree is called the local outlier factor (LOF) of an object. It is local in that the degree depends on how isolated the object is with respect to the surrounding neighborhood. We give a detailed formal analysis showing that LOF enjoys many desirable properties. Using real-world datasets, we demonstrate that LOF can be used to find outliers which appear to be meaningful, but can otherwise not be identified with existing approaches. Finally, a careful performance evaluation of our algorithm confirms we show that our approach of finding local outliers can be practical.},
journal = {SIGMOD Rec.},
month = may,
pages = {93–104},
numpages = {12},
keywords = {outlier detection, database mining}
}

@inproceedings{lof,
author = {Breunig, Markus M. and Kriegel, Hans-Peter and Ng, Raymond T. and Sander, J\"{o}rg},
title = {LOF: identifying density-based local outliers},
year = {2000},
isbn = {1581132174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/342009.335388},
doi = {10.1145/342009.335388},
abstract = {For many KDD applications, such as detecting criminal activities in E-commerce, finding the rare instances or the outliers, can be more interesting than finding the common patterns. Existing work in outlier detection regards being an outlier as a binary property. In this paper, we contend that for many scenarios, it is more meaningful to assign to each object a degree of being an outlier. This degree is called the local outlier factor (LOF) of an object. It is local in that the degree depends on how isolated the object is with respect to the surrounding neighborhood. We give a detailed formal analysis showing that LOF enjoys many desirable properties. Using real-world datasets, we demonstrate that LOF can be used to find outliers which appear to be meaningful, but can otherwise not be identified with existing approaches. Finally, a careful performance evaluation of our algorithm confirms we show that our approach of finding local outliers can be practical.},
booktitle = {Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data},
pages = {93–104},
numpages = {12},
keywords = {outlier detection, database mining},
location = {Dallas, Texas, USA},
series = {SIGMOD '00}
}



@misc{deeplearninganomalydetection,
      title={Deep Learning for Anomaly Detection: A Survey}, 
      author={Raghavendra Chalapathy and Sanjay Chawla},
      year={2019},
      eprint={1901.03407},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1901.03407}, 
}

@misc{ibmAnomalyDetection,
	author = {Camilo Quiroz-Vázquez},
	title = {{A}nomaly {D}etection in {M}achine {L}earning: {E}xamples, {A}pplications \& {U}se {C}ases | {I}{B}{M} --- ibm.com},
	URL = {https://www.ibm.com/think/topics/machine-learning-for-anomaly-detection},
	year = {},
	note = {[Accessed 12-05-2025]},
}

@article{unsupervisedAnomalyDetection,
    doi = {10.1371/journal.pone.0152173},
    author = {Goldstein, Markus AND Uchida, Seiichi},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data},
    year = {2016},
    month = {04},
    volume = {11},
    url = {https://doi.org/10.1371/journal.pone.0152173},
    pages = {1-31},
    abstract = {Anomaly detection is the process of identifying unexpected items or events in datasets, which differ from the norm. In contrast to standard classification tasks, anomaly detection is often applied on unlabeled data, taking only the internal structure of the dataset into account. This challenge is known as unsupervised anomaly detection and is addressed in many practical applications, for example in network intrusion detection, fraud detection as well as in the life science and medical domain. Dozens of algorithms have been proposed in this area, but unfortunately the research community still lacks a comparative universal evaluation as well as common publicly available datasets. These shortcomings are addressed in this study, where 19 different unsupervised anomaly detection algorithms are evaluated on 10 different datasets from multiple application domains. By publishing the source code and the datasets, this paper aims to be a new well-funded basis for unsupervised anomaly detection research. Additionally, this evaluation reveals the strengths and weaknesses of the different approaches for the first time. Besides the anomaly detection performance, computational effort, the impact of parameter settings as well as the global/local anomaly detection behavior is outlined. As a conclusion, we give an advise on algorithm selection for typical real-world tasks.},
    number = {4},
}

@book{dataClustering,
author = {Gan, Guojun and Ma, Chaoqun and Wu, Jianhong},
title = {Data Clustering: Theory, Algorithms, and Applications},
publisher = {Society for Industrial and Applied Mathematics},
year = {2007},
doi = {10.1137/1.9780898718348},
address = {},
edition   = {},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9780898718348},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9780898718348}
}

@ARTICLE{katzBackoff,
  author={Katz, S.},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={Estimation of probabilities from sparse data for the language model component of a speech recognizer}, 
  year={1987},
  volume={35},
  number={3},
  pages={400-401},
  abstract={The description of a novel type of m-gram language model is given. The model offers, via a nonlinear recursive procedure, a computation and space efficient solution to the problem of estimating probabilities from sparse data. This solution compares favorably to other proposed methods. While the method has been developed for and successfully implemented in the IBM Real Time Speech Recognizers, its generality makes it applicable in other areas where the problem of estimating probabilities from sparse data arises.},
  keywords={Natural languages;Speech recognition;Recursive estimation;Maximum likelihood estimation;Probability;Statistics;Speech processing;Acoustic signal processing},
  doi={10.1109/TASSP.1987.1165125},
  ISSN={0096-3518},
  month={March},}

@inproceedings{chen-goodman-1996-empirical,
    title = "An Empirical Study of Smoothing Techniques for Language Modeling",
    author = "Chen, Stanley F.  and
      Goodman, Joshua",
    booktitle = "34th Annual Meeting of the Association for Computational Linguistics",
    month = jun,
    year = "1996",
    address = "Santa Cruz, California, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P96-1041/",
    doi = "10.3115/981863.981904",
    pages = "310--318"
}

@misc{huang2025deeplearningadvancementsanomaly,
      title={Deep Learning Advancements in Anomaly Detection: A Comprehensive Survey}, 
      author={Haoqi Huang and Ping Wang and Jianhua Pei and Jiacheng Wang and Shahen Alexanian and Dusit Niyato},
      year={2025},
      eprint={2503.13195},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2503.13195}, 
}

@Article{DL-worth-it,
AUTHOR = {Rewicki, Ferdinand and Denzler, Joachim and Niebling, Julia},
TITLE = {Is It Worth It? Comparing Six Deep and Classical Methods for Unsupervised Anomaly Detection in Time Series},
JOURNAL = {Applied Sciences},
VOLUME = {13},
YEAR = {2023},
NUMBER = {3},
ARTICLE-NUMBER = {1778},
URL = {https://www.mdpi.com/2076-3417/13/3/1778},
ISSN = {2076-3417},
ABSTRACT = {Detecting anomalies in time series data is important in a variety of fields, including system monitoring, healthcare and cybersecurity. While the abundance of available methods makes it difficult to choose the most appropriate method for a given application, each method has its strengths in detecting certain types of anomalies. In this study, we compare six unsupervised anomaly detection methods of varying complexity to determine whether more complex methods generally perform better and if certain methods are better suited to certain types of anomalies. We evaluated the methods using the UCR anomaly archive, a recent benchmark dataset for anomaly detection. We analyzed the results on a dataset and anomaly-type level after adjusting the necessary hyperparameters for each method. Additionally, we assessed the ability of each method to incorporate prior knowledge about anomalies and examined the differences between point-wise and sequence-wise features. Our experiments show that classical machine learning methods generally outperform deep learning methods across a range of anomaly types.},
DOI = {10.3390/app13031778}
}

@article{chi-square,
title = "An anomaly detection technique based on a chi-square statistic for detecting intrusions into information systems",
abstract = "An intrusion into an information system compromises its security (e.g. availability, integrity and confidentiality) through a series of events in the information system. Intrusive events often show departures (anomalies) from normal events in an information system. This paper presents an anomaly detection technique based on a chi-square statistic. This technique builds a profile of normal events in an information system-a norm profile computes the departure of events in the recent past from the norm profile and detects a large departure as an anomaly-a likely intrusion. This technique was tested for its performance in distinguishing normal events from intrusive events in an information system. The test results demonstrated the promising performance of this technique for intrusion detection in terms of a low false alarm rate and a high detection rate. Intrusive events were detected at a very early stage.",
keywords = "Chi-square statistic, Computer security, Intrusion detection, Multivariate analysis",
author = "Nong Ye and Qiang Chen",
year = "2001",
month = mar,
doi = "10.1002/qre.392",
language = "English (US)",
volume = "17",
pages = "105--112",
journal = "Quality and Reliability Engineering International",
issn = "0748-8017",
publisher = "John Wiley and Sons Ltd",
number = "2",
}

@misc{hendrycks2018baseline,
      title={A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks}, 
      author={Dan Hendrycks and Kevin Gimpel},
      year={2018},
      eprint={1610.02136},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/1610.02136}, 
}

@inproceedings{HBOS,
author = {Goldstein, Markus and Dengel, Andreas},
year = {2012},
month = {09},
pages = {},
title = {Histogram-based Outlier Score (HBOS): A fast Unsupervised Anomaly Detection Algorithm}
}

@BOOK{aima,
    title = {Artificial intelligence},
    author    = {Russell, Stuart and Norvig, Peter},
 publisher  =  {Pearson},
  edition   =  {4},
  month     =  {nov},
  year      =  {2020},
  address   = {Upper Saddle River, NJ},
  language  = {en}
}

@misc{hhlaIntermodalTransport,
	author = {HHLA},
	title = {{I}ntermodal {T}ransport - {H}{H}{L}{A} --- hhla.de},
	URL = {https://hhla.de/en/company/subsidiaries/intermodal-transport},
	year = {},
	note = {[Accessed 10-05-2025]},
}
@misc{hhlaIntermodalLogistics,
	author = {HHLA},
	title = {{I}ntermodal {L}ogistics - {H}{H}{L}{A} --- hhla.de},
	URL = {https://hhla.de/en/the-power-of-networks/intermodal-logistics},
	year = {},
	note = {[Accessed 10-05-2025]},
}

@misc{hhlaPowerNetworks,
	author = {HHLA},
	title = {{T}he {P}ower of {N}etworks - {H}{H}{L}{A} --- hhla.de},
	URL = {https://hhla.de/en/the-power-of-networks},
	year = {},
	note = {[Accessed 11-05-2025]},
}

@misc{metransTerminal,
	author = {METRANS},
	title = {{M}{E}{T}{R}{A}{N}{S} {T}erminal \& {D}epot {S}olutions; {M}{E}{T}{R}{A}{N}{S} --- metrans.eu},
	URL = {https://metrans.eu/solutions/metrans-terminal-deport-solutions/},
	year = {2013},
	note = {[Accessed 11-05-2025]},
}

@misc{metransIntermodal,
	author = {METRANS},
	title = {{M}{E}{T}{R}{A}{N}{S} {I}ntermodal {S}olutions; {M}{E}{T}{R}{A}{N}{S} --- metrans.eu},
	URL = {https://metrans.eu/solutions/metrans-intermodal-solutions/},
	year = {2013},
	note = {[Accessed 11-05-2025]},
}
@article{intermodalTransportOverview,
author = {Bektas, Tolga and Crainic, Teodor Gabriel},
year = {2007},
month = {02},
pages = {28-1},
title = {Brief Overview of Intermodal Transportation},
isbn = {9780849330537},
doi = {10.1201/9780849330537.ch28},
journal={Logistics Engineering Handbook}
}

@article{intermodalTransport,
author = {Crainic, Teodor Gabriel and Kim, K.H.},
year = {2006},
month = {01},
pages = {467-537},
title = {Intermodal Transportation},
volume = {14},
journal = {Transportation}
}

@misc{codenowReleaseNotes,
	author = {CodeNOW Blog},
	title = {{R}elease {N}otes {C}ode{N}{O}{W} 6.14 – {S}eptember 2022 --- codenow.org},
	URL = {https://www.codenow.org/blog/release-notes-codenow-6-14-september-2022},
	year = {},
	note = {[Accessed 11-05-2025]},
}
@misc{WhyCodeNOW,
	author = {CodeNOW Docs},
	title = {{W}hy {C}ode{N}{O}{W} | {C}ode{N}{O}{W} {D}ocumentation --- docs.codenow.com},
	URL = {https://docs.codenow.com/why-codenow},
	year = {},
	note = {[Accessed 11-05-2025]},
}

@misc{WhatCodeNOW,
	author = {CodeNOW Docs},
	title = {{W}hat is {C}ode{N}{O}{W} | {C}ode{N}{O}{W} {D}ocumentation --- docs.codenow.com},
	URL = {https://docs.codenow.com/what-is-codenow},
	year = {},
	note = {[Accessed 11-05-2025]},
}

@misc{MessageQueue,
	author = {Keerthi Rangan},
	title = {{W}hat {I}s a {M}essage {Q}ueue? {H}ow to {U}se {I}t in {D}istributed {S}ystems},
	URL = {https://www.g2.com/articles/message-queue-mq},
	year = {2024},
	note = {[Accessed 11-05-2025]},
}

@misc{RabbitMQ,
	author = {RabbitMQ},
	title = {{R}abbit{M}{Q}: {O}ne broker to queue them all | {R}abbit{M}{Q} --- rabbitmq.com},
	URL = {https://www.rabbitmq.com/},
	year = {},
	note = {[Accessed 11-05-2025]},
}

@misc{mediumConfusionMatrix,
	author = {Fabiola Uwashema},
	title = {{C}onfusion matrix, {P}recision, {R}ecall, and {F}1 {S}core {P}erformance {M}etrics for log anomaly detection --- medium.com},
	howpublished = {\url{https://medium.com/ibm-watson-aiops/confusion-matrix-precision-recall-and-f1-score-performance-metrics-for-log-anomaly-detection-1a187a17fca9}},
	year = {2022},
month = {Jan},
	note = {[Accessed 11-05-2025]},
}

@article{Chadha2020DistilledEvaluationMetrics,
  title   = {Evaluation Metrics},
  author  = {Chadha, Aman},
  journal = {Distilled AI},
  year    = {2020},
  URL    = {https://aman.ai/primers/ai/evaluation-metrics/\#precision-and-recall-vs-sensitivity-and-specificity}
}