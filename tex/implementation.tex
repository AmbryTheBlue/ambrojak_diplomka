% !TEX program = optex
% !TEX root = ambrojak-thesis-masters.tex
\label[implementation]
\chap Implementation
This chapter details the implementation and system architecture of the project, covering the technical stack utilized, the machine learning models and pipelines developed, and the combined workflow for anomaly detection. The technical foundation includes Python and various libraries such as Jupyter, scikit-learn, and Keras, alongside tools for managing the machine learning lifecycle like MLflow, and version control systems Git and GitLab.

\sec Technical stack used

\secc Python, Jupyter, scikit-learn, Keras
Unexpectadly Python was selected as our programming language of choice. The reasons for this are quick development, flexibility, and that it has many ready-to-use machine learning libraries. For example scikit-learn is an ``open source, commercially usable machine learning library built on NumPy, SciPy, and matplotlib.''\urlnote{https://scikit-learn.org/stable/index.html}

Another library we have used is Keras that is very useful for Neural Networks.\urlnote{https://keras.io/} And for quick testing Jupyter Notebooks have been used. They were especailly usefull in combination with JupyerHub that allowed me to work on the servers with access to data and I did not have to download them manually.\urlnote{https://jupyter.org/hub}

\secc MLflow
MLflow is an open-source platform for managing the machine learning lifecycle, including experimentation, reproducibility, deployment, and monitoring. It provides tools for tracking experiments, packaging models, and managing model deployments across diverse frameworks and environments.

With its modular design, MLflow supports collaboration and scalability, streamlining workflows for teams working on data-driven projects.\urlnote{https://mlflow.org/docs/latest/index.html}

\secc Git \& GitLab
In this project, Git and GitLab are used for version control, branching, and  saving code to ``cloud'' and synchronization. A short description of them is provided here. \fnote{but if you are unaware of them, studying them is suggested over reading this piece.}

{\bf Git} is a distributed version control system that tracks code changes, supports branching, and enables collaborative development with a decentralized structure, ensuring a full version history and offline work.\urlnote{https://git-scm.com/}

{\bf GitLab} is a web-based platform built on Git that integrates version control, CI / CD, and project management. It supports collaboration, code reviews, and automation, making it ideal for DevOps and team workflow.\urlnote{https://about.gitlab.com/}

\sec Models and pipelines
This section provides more precise description of the steps involved in our machine learning pipeline. This includes detailing preprocessing, vectorization and synthetic anomaly generation. With some small illustrative code snippets, the key files are in full located in the Appendix \ref[src-snippets].\fnote{For more curious readers, the source code in full is located in \url{https://github.com/AmbryTheBlue/ambrojak_diplomka_code}}

At the end of this section is a description of full workflow.

\begtt \hisyntax{Python}
def create_pipelines(X_cols, estimators=None):
    """
    Creates a pipelines with text preprocessing and the given estimators.
    """
    if not estimators:
        estimators = [
            ("LogRegression", LogisticRegression()),
            ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),
            ('xgb', XGBClassifier(use_label_encoder=False,
             eval_metric='logloss', random_state=42)),
            ('lgbm', LGBMClassifier(use_label_encoder=False,
             random_state=42, verbosity=-1)),
            # ('svc', SVC(probability=True, random_state=42)),
            # probability=True enables predict_proba
            #Probably takes the longest time
            ('KerasNNClassifier', KerasClassifier(
                model=build_model, epochs=5, verbose=0)),
        ]
    voting = VotingClassifier(
        estimators=estimators,
        voting="soft",
    )

    cols = [('BagOfWords' + col, TfidfVectorizer(), col) for col in X_cols]
    basic_pipeline = [
        ('TextPreprocessor', TextPreprocessor(X_cols)),
        ('VectorizeText', ColumnTransformer(cols)),
    ]
    pipelines = []
    for estimator in estimators + [('VotingClassifier', voting)]:
        pipelines.append(Pipeline(basic_pipeline + [estimator]))
    return pipelines
\endtt

\secc Preprocessing
In the preprocessing stage, all textual fields undergo normalization to eliminate superficial variations that do not affect semantics. Company and client names, sender and receiver identifiers, goods descriptions (in multiple languages), and HS codes are first stripped of leading and trailing whitespace, with consecutive spaces collapsed into a single space. We then remove diacritics and map every character to its ASCII equivalent, which ensures that entries such as “Název společnosti”\fnote{In English ``Company Name''}, “NAZEV SPOLECNOSTI ”, and “ nazev       spolecnosti ” are treated identically. Special characters beyond alphanumeric symbols are also dropped or replaced consistently.

\begtt \hisyntax{Python}
def preprocess_text(self, text):
    # Normalize and replace accented chars with ASCII equivalents
    text = unicodedata.normalize('NFKD', text)
    text = text.encode('ascii', 'ignore').decode('ascii')
    text = re.sub(r'\s', ' ', text)
    text = text.upper()
    text = re.sub(r'[^A-Z0-9]', ' ', text)
    text = re.sub(r' +', ' ', text)
    return text.strip()
\endtt

For binary indicator columns—such as those denoting the presence of an additional billing reference or specific container markers (BHT/TCC/ZAPP)—we map all variants (for example, “X” an actual reference string, an empty string, or just ''NULL'') into a clean {0, 1} encoding. Chassis types, originally text strings describing container categories, are subjected to the same whitespace and casing normalization rules. Finally, heating temperature values, which were provided as inconsistent strings such as '+40°C', '40 ° C', '+40C', '40', '40 °', or even blank entries, are processed by stripping non-digit symbols and whitespace, then parsed into numeric Celsius values; any unparsable values are marked as missing.

\begtt \hisyntax{Python}
if self.target_col in ["HAS_HEAING", "HAS_CUSTOMS_NUMBER"]:
    X[self.target_col] = X[self.target_col].map(
        {None: 0.0, ' ': 0.0, 'X': 1.0}).fillna(X[self.target_col])
    X[self.target_col] = pd.to_numeric(
        X[self.target_col], errors='coerce')
elif self.target_col in ["TEMP_FROM", "TEMP_TO", "TEMPERATURE"]:
    X[self.target_col] = X[self.target_col].apply(lambda x: int(
    str(x).replace(
    "°","").replace("C","").replace('+','').strip()) 
            if pd.notnull(x) and str(x).replace("°", "").replace("C",
            "").replace('+','').strip().isdigit() 
            else -1000 # np.nan # causes problems later
            # create dummy value that is far away from everything
            )
    X[self.target_col] = pd.to_numeric(
        X[self.target_col], errors='coerce')
elif self.target_col in ["ADITIONAL_REF_IM", "ADDITIONAL_REF_EX"]:
    X[self.target_col] = X[self.target_col].astype(str)
    X[self.target_col] = X[self.target_col].apply(
        lambda x: 0 if pd.isna(x) or str(x).strip() == '' else 1)
# And so on for other anomalies
\endtt

\secc Vectorization
After cleaning, each text feature is converted into a numeric representation via an independent Bag-of-Words (BoW) transformer. We chose the BoW approach because company names often differ only by suffix or country, and shared tokens capture their relatedness. This method also tolerates minor typos by overlapping unigrams, and treats high-frequency tokens equally, which is desirable when even common words (such as the name of a major client) carry meaningful information rather than noise. \fnote{For this reason we have opted out of using TF-IDF vectorization.} The resulting sparse vectors, one per feature, are then horizontally concatenated into a single high-dimensional input vector.

Because the target columns are binary or categorical flags, they are handled separately using a simple "LabelEncoder" that maps each class to an integer code rather than using BoW.

\secc Synthetic anomaly generators
To address the scarcity of real-world anomalies and stress-test our detection models, we generate synthetic anomalies by randomly corrupting target labels in otherwise normal records. For training set we do not introduce any synthetic entries. However for our testing set we generate for each record its anomalous counterpart by changing the label of target column.

This procedure simulates errors such as missing or mistyped flags in production orders while preserving the data’s overall structure. Because all features are Label-Encoded prior to injection, these synthetic anomalies integrate seamlessly into the downstream pipeline.

\begtt \hisyntax{Python}
def create_shuffled_mapping(categories):
    """
    Creates a shuffled mapping for anomaly generation.
    """
    shuffled = categories.copy()
    if len(categories) <= 1:
        return dict(zip(categories, categories))
    while True:
        np.random.shuffle(shuffled)
        if not np.any(shuffled == categories):
            break
    return dict(zip(categories, shuffled))
\endtt

Using them only on the testing sets forbids us from introducing any False anomalies into our training data. That is, we are trying to avoid a situation where for given features there may be several valid values of the target column. And our ``anomalous'' version with swapped labels would still be completely normal in reality.

\sec Combined Workflow

\begitems
* For a chosen anomaly type load appropriate data from Metrans database

* Preprocess the target column, apply "LabelEncoder" if necessary (this ensures labels are consistent in training and testing sets).

* Split the data into training and test sets, where testing compromises 10\%

* For a selected estimators (such as Random Forest or Neural Network) apply our sklearn pipeline that does the following:

\begitems \style a
* Preprocess feature columns
* Vectorize those columns
* Train the estimator
* generate and anomalous dataset from testing dataset
* Apply the pipeline's predict function on testing and anomalous dataset
* Evaluate the predictions
* Save the TP, FP, TN, FN
\enditems

* Compare the performance of different estimators on our chosen metric - generally 
 F1 (but it could be Precision, Recall, Accuracy etc.)

 * Select the best performing model and save it using MLflow for future use.
\enditems


Overall he machine learning pipeline involves several key steps: preprocessing textual data to normalize variations, vectorizing text features into a numerical format using a Bag-of-Words approach, and generating synthetic anomalies to robustly test the detection models. The preprocessing stage handles different data types, including textual fields, binary indicators, chassis types, and temperature values, applying specific normalization and encoding techniques to ensure data consistency. Vectorization converts cleaned text into sparse numerical vectors, which are then combined into a single input vector for the models. Synthetic anomalies are created by corrupting target labels in test data to simulate real-world errors without affecting the training set.

In the next chapter, we describe the evaluation process of the results of these pipelines for various models, approaches, and anomalies. And show the results with additional comments.