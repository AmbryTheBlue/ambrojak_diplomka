% !TEX program = optex
% !TEX root = ambrojak-thesis-masters.tex
\chap Approaches and Model Design for Anomaly Detection in Metrans Orders

In this chapter, we present three distinct approaches to anomaly detection tailored for structured, tabular data as found in transport order records. Each method captures a different facet of unexpected behaviour: Misclassification Detection identifies inconsistencies between model predictions and recorded labels; Frequency-Based Outlier Detection flags rare combinations of categorical features; and Confidence-Based Anomaly Detection detects uncertain predictions indicative of atypical inputs. Together, these methods provide a complementary toolkit suited to the categorical, multi-modal, and label-sparse nature of real-world logistics data.

\label[MD]
\sec Misclassification Detection
Misclassification detection is an approach to anomaly identification that leverages a supervised classifier trained exclusively on non-anomalous data. The core idea is straightforward: a model is trained to predict a categorical target variable representing the expected outcome (e.g., heating type, chassis type) for each transport order. At inference time, the model's predicted class is compared against the actual recorded class present in the data. If the prediction diverges from the observed label, the data point is considered anomalous.

This technique is commonly associated with open-set recognition and out-of-distribution (OOD) detection in supervised learning contexts. While the classifier is not exposed to anomalies during training, it is assumed that such anomalous instances will result in incorrect or low-confidence predictions. Usage of confidence is further discussed in \ref[CBAD]. The premise here aligns with the idea that misclassified  data points are often indicative of input patterns that differ fundamentally from those observed during training \cite[hendrycks2018baseline].

TODO - add equation\rfc{TODO - add equation}


\secc Advantages and Limitations
One advantage of this approach is its simplicity and ease of implementation. Since the system relies on standard supervised classification pipelines, it integrates seamlessly into the existing model infrastructure, especially within the scikit-learn ecosystem. Moreover, this method provides high interpretability: when an anomaly is detected, the predicted class offers a direct suggestion as to what the "correct" category might have been, facilitating manual inspection and correction.

However, this approach is subject to several critical limitations. A notable issue is the potential for multi-modal consistency. In real-world logistics data, it is often the case that multiple class labels may be valid for the same set of features. For instance, a client may legitimately use either a 20-foot or a 40-foot container type depending on the specific goods or logistics partner involved. In such cases, a mismatch between predicted and observed labels does not necessarily imply an error, leading to false positive detections.

Furthermore, misclassification detection assumes that the classifier is well-calibrated and that the training data sufficiently captures the diversity of valid cases. In practice, this assumption may not hold, especially in dynamic business environments such as intermodal logistics, where new routes, clients, or service configurations may emerge regularly.

\secc Applicability in This Thesis
In the context of anomalies defined in previous chapter, misclassification detection serves as a baseline method for identifying anomalous transport orders. The classifier is trained using historical, verified (i.e., assumed error-free) data, and evaluated on newly submitted or manually modified orders. This method is particularly suitable for use cases where the target variable is relatively stable and categorical (e.g., heating type, presence of BHT/ ZAPP/ TCC number). However, for features that naturally support multiple valid values per context, additional anomaly detection strategies are required, such as frequency-based outlier scoring (\ref[FBOD]) or confidence calibration (\ref[CBAD], to reduce the rate of false alarms.

\label[CBAD]
\sec Confidence-Based Anomaly Detection (CBAD)
Confidence-Based Anomaly Detection (CBAD) is a method that assesses the reliability of a model’s prediction in relation to the actual observed label. It is based on the premise that a well-calibrated classifier should assign a high probability to the correct class, assuming the input lies within the distribution observed during training. When this confidence is low, the model effectively signals that it is uncertain about the correctness of the given label. Such cases are treated as potential anomalies.

This approach is closely related to the Maximum Softmax Probability (MSP) technique \cite[hendrycks2018baseline], which was originally developed for detecting out-of-distribution inputs in image classification models. However, the general principle is directly applicable to categorical decision problems, including the transport order domain investigated in this thesis.

\secc Model Requirements and Relation to Misclassification Detection
This method can be applied using the same classification models used for Misclassification Detection, see Section \ref[MD].

Provided that the models expose class probabilities via a predic_proba interface or an equivalent mechanism. If the underlying classifier does not produce well-calibrated probabilities, such as decision trees, support vector machines, or gradient boosting models, probability calibration techniques can be applied. The most common options include Platt scaling and isotonic regression, both available in scikit-learn via the CalibratedClassifierCV wrapper \urlnote{https://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html}


\secc Selection of the Threshold Parameter τ
The choice of the threshold $τ$ is critical for determining the sensitivity of the detector. Several methods exist for selecting this parameter in a principled way:
\begitems
* Validation-based optimization: One common approach is to select $\tau$ based on F1 score on a labeled validation dataset, especially one augmented with synthetic anomalies. This approach balances precision and recall, making it well-suited to imbalanced settings.

* ROC-based selection: Alternatively, the optimal threshold may be chosen by analyzing the Receiver Operating Characteristic (ROC) curve and selecting the value of $τ$ that maximizes Youden’s J statistic 

* Cost-based methods: In application domains where the costs of false positives and false negatives are known or can be estimated, one may define a cost function and choose $τ$ to minimize expected loss.

* Conformal prediction: Finally, more advanced techniques such as conformal prediction can be used to convert confidence scores into p-values, providing statistically valid thresholds under the assumption of exchangeable (i.i.d.) data. This approach is theoretically grounded and supports user-defined risk levels
\enditems

In practice, the threshold will probably be later adjusted based on the models performance on new live data.

\secc Applicability in Metrans Anomalies
In the context of this work, confidence-based anomaly detection serves as a lightweight method for capturing uncertain decisions made by the classifier. It complements the hard-decision strategy of Misclassification Detection and the distributional rarity approach of Frequency-Based Outlier Detection (\ref[FBOD]). When used in tandem, these methods provide a comprehensive framework for identifying anomalous transport orders using different perspectives on what constitutes “unexpected” behavior.

\label[FBOD]
\sec  Frequency-based outlier detection
Frequency-based outlier detection (FBOD) is a non-parametric, unsupervised method for identifying anomalies in categorical or mixed-type data. This approach is grounded in the assumption that valid observations—such as transport orders with correct field combinations—occur frequently in the training data, while anomalous or erroneous cases tend to be rare or entirely absent. Consequently, orders that contain uncommon combinations of categorical values (e.g., unusual client–route–heating-type configurations) are flagged as potential anomalies.

This method is conceptually related to the Histogram-Based Outlier Score (HBOS) introduced by Goldstein and Dengel (2012)\cite[HBOS], but is applied here to joint categorical statistics rather than independent numerical features. While HBOS decomposes multivariate data into univariate histograms and aggregates their scores under a naïve independence assumption, this work's implementation maintains joint counts for selected feature combinations to better reflect categorical dependencies present in logistics data.

\rfc{Předělat url poznámky pod čarou na korektní BiBteX notace}

\secc Advantages and Limitations

This method offers several practical advantages. It is highly interpretable—domain experts can easily verify whether a flagged combination is indeed uncommon or erroneous. Additionally, it is computationally efficient and well-suited for online use, as frequency counts can be incrementally updated in real time. This makes it an ideal candidate for deployment in a streaming context.

Another major advantage is its tolerance to multi-modality. Unlike classification-based methods, which assume a single correct class per input context, frequency-based detectors accommodate multiple frequent class values per key, making them robust to legitimate variation in client behavior.

Nevertheless, there are inherent limitations. The method requires the selection of an appropriate set of categorical features to define the key. If too few features are selected, anomalies may not stand out; if too many, the frequency table becomes sparse, increasing the risk of false positives due to low support. This issue solved by treating all unseen feature keys as okay data. Additionally, this approach does not model interdependencies beyond the selected keys.


TODO - definetly add equation as it is a custom models\rfc{TODO - definetly add equation}


\secc Applicability in This Thesis
In this thesis, frequency-based outlier detection is applied to several anomaly detection tasks involving categorical decision fields, such as heating type and chassis selection. The technique is implemented directly using pandas for offline analysis and is compatible with integration into a real-time streaming pipeline due to its low computational overhead. While it is not based on probabilistic modeling, it complements other methods by capturing rare-but-valid edge cases that may be overlooked by classifiers.

\sec Back-Off Smoothing for Sparse Frequency Estimation
In practice, the effectiveness of frequency-based outlier detection (as described in Section \ref[FBOD]) is limited by the sparsity of high-cardinality categorical combinations. When a transport order contains a feature configuration that has not previously occurred in the training data, the system—if relying solely on exact frequency matches—fails to produce a score. To address this limitation, we adopt a back-off smoothing strategy, inspired by techniques developed for n-gram language models and sparse contingency table estimation \cite[katzBackoff,chen-goodman-1996-empirical].

Back-off smoothing provides a principled mechanism for estimating probabilities (or frequencies) of unseen or rare events by recursively falling back to less specific contexts. In our implementation, this corresponds to progressively reducing the dimensionality of the feature combination $k=(f_1, f_2, f_3)$ used for frequency lookup.

Specifically, the system attempts to evaluate the anomaly score using the full feature key. If this key is absent from the frequency table, it backs off to a lower-order projection—e.g., dropping one or more features—until a valid count is found. For example, given a triple $(f_1, f_2, f_3)$ the lookup proceeds in the following order:
$$
(f_1, f_2, f_3), (f_1, f_2), (f_1, f_3), (f_2, f_3), (f_1), (f_2), (f_3)
$$
The first successful match determines the anomaly score. If no match is found at any level, the order is treated as normal. The reason being that if no sender and reciever matches this new order then it is likely a new client where we lack any sort of data. In general application, it would have been treated as maximally anomalous.

\rfc{Přidat specifické přístupy pro teplotu}